{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Reinforcement Learning\n",
    "\n",
    "## Task 1 (50 points): Formulating Real World Problems as MDPs\n",
    "\n",
    "#### Prompt\n",
    "We discussed how we can formulate RL problems as an MDP. Describe any\n",
    "real-world application that can be formulated as an MDP. Describe the state space, action\n",
    "space, transition model, and rewards for that problem. You do not need to be precise in the\n",
    "description of the transition model and reward (no formula is needed). Qualitative description\n",
    "is enough.\n",
    "\n",
    "#### Response\n",
    "\n",
    "## Task 2 (50 points): Reinforcement Learning in concrete domains\n",
    "\n",
    "#### Prompt\n",
    "RL is used in various sectors - Healthcare, recommender systems and trading\n",
    "are a few of those. Pick one of the three areas. Explain one of the problems in any of these\n",
    "domains that can be more effectively solved by reinforcement learning. Find an open-source\n",
    "project (if any) that has addressed this problem. Explain this project in detail.\n",
    "\n",
    "#### Response\n",
    "\n",
    "## Task 3 (100 points): Implementation of Q-Learning for Tik Tak Toe.\n",
    "\n",
    "#### Prompt\n",
    "Implement the game of tic-tac-toe (write a class that implements an agent\n",
    "playing Tic Tac Toe and learning its Q function) using the Q-learning technique (see the\n",
    "resources/links provided in class for more details). Clearly describe your evaluation metric and\n",
    "demonstrate a few runs. You might need to use some online resources to proceed on this. Do\n",
    "not forget to cite those.\n",
    "\n",
    "#### Response\n",
    "One of the main resources I used was [this article](https://towardsdatascience.com/reinforcement-learning-q-learning-with-illegal-actions-from-scratch-19759146c8bf), which describes how you should do Q-learning when your available actions are limited on a state by state basis. I.E., in tic-tak-toe, you are not allowed to put a mark on top of another mark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "actionNames = {\n",
    "    0: \"(0, 0) Upper Left\",\n",
    "    1: \"(1, 0) Upper Center\",\n",
    "    2: \"(2, 0) Upper Right\",\n",
    "    3: \"(0, 1) Middle Left\",\n",
    "    4: \"(1, 1) Middle Center\",\n",
    "    5: \"(2, 1) Middle Right\",\n",
    "    6: \"(0, 2) Lower Left\",\n",
    "    7: \"(1, 2) Lower Center\",\n",
    "    8: \"(2, 2) Lower Right\",\n",
    "}\n",
    "\n",
    "actions = actionNames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Board drawing utility\n",
    "def drawBoard(board, saveName=None):\n",
    "    labelMap = np.vectorize(lambda value: {1:\"X\", -1:\"0\", 0:\" \"}[value])\n",
    "    shapedBoard = np.reshape(board, (3, 3))\n",
    "    labels = labelMap(shapedBoard)\n",
    "    sns.heatmap(shapedBoard, cmap=\"bwr\", annot=labels, \n",
    "        linewidth=.5, linecolor=\"black\", fmt=\"\", cbar=False,\n",
    "        square=True, xticklabels=False, yticklabels=False)\n",
    "    if saveName:\n",
    "        plt.savefig(f\"figs/{saveName}\")\n",
    "\n",
    "#Testing\n",
    "drawBoard([1, 1, 1, 0, -1, 0, -1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of a tik tak toe class, we pre-generate the whole game tree to speed up checking the winner since ticktacktoe is a reasonably small game\n",
    "\n",
    "#Maps board arrays to states to save us space, we reuse state nodes if we encounter a state that already exists\n",
    "boardToState = {}\n",
    "\n",
    "class GameStateNode():\n",
    "    def __init__(self):\n",
    "        #if we are a termination state (leaf node), self.winner is who won, X or O, else is None if draw or not leaf node\n",
    "        self.winner = 0  \n",
    "        \n",
    "        #an dict representing the map between actions the child states\n",
    "        self.children = {}\n",
    "        \n",
    "        #The board representation as an array of 9 positions, we can use this for drawing any state\n",
    "        #0 represents an empty box, 1 represents a X, -1 represents a 0\n",
    "        self.board = None\n",
    "\n",
    "\n",
    "#There are only 8 win masks, faster to index all of them rather than add every time\n",
    "winMasks = np.array([\n",
    "    [1, 1, 1, 0, 0, 0, 0, 0, 0], #Horizontal wins\n",
    "    [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "    [1, 0, 0, 1, 0, 0, 1, 0, 0], #Vertical Wins\n",
    "    [0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 1, 0, 0, 0, 1], #Diagonal wins\n",
    "    [0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
    "])\n",
    "\n",
    "def win(board):\n",
    "    for winMask in winMasks:\n",
    "        maskedSum = np.sum(winMask*board)\n",
    "        if maskedSum == 3:\n",
    "            return 1\n",
    "        elif maskedSum == -3:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def buildGameTree(node, board, player):\n",
    "    node.winner = win(board)\n",
    "    if node.winner:             #if the game isn't over, create new branches for all actions\n",
    "        return\n",
    "    for action in actions:\n",
    "        if board[action] == 0:  #if move is legal\n",
    "            newBoard = np.copy(board)\n",
    "            newBoard[action] = player\n",
    "            newBoard.flags.writeable = False\n",
    "            if newBoard.tobytes() in boardToState:             #Reuse trees for states we've already seen\n",
    "                newNode = boardToState[newBoard.tobytes()]     \n",
    "            else:                                                   #Create new tree if we have not seen it\n",
    "                newNode = GameStateNode()                    \n",
    "                newNode.board = newBoard\n",
    "                buildGameTree(newNode, newBoard, -player)\n",
    "                boardToState[newBoard.tobytes()] = newNode\n",
    "            node.children[action] = newNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5478"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = GameStateNode()\n",
    "emptyBoard = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "boardToState[emptyBoard.tobytes()] = root\n",
    "buildGameTree(root, emptyBoard, 1)\n",
    "\n",
    "#We expect for tic-tac-toe to get 5477 valid states according to\n",
    "#https://stackoverflow.com/a/25358690/6342516\n",
    "len(boardToState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing my game tree\n",
    "import networkx as nx\n",
    "\n",
    "gameGraph = nx.DiGraph()\n",
    "for boardBytes, node in boardToState.items():\n",
    "    gameGraph.add_node(boardBytes, children=len(node.children), state=str(node.board), depth=np.count_nonzero(node.board), winner=node.winner)\n",
    "for boardBytes, node in boardToState.items():\n",
    "    for _, child in node.children.items():\n",
    "        gameGraph.add_edge(boardBytes, child.board.tobytes())\n",
    "\n",
    "nx.write_gexf(gameGraph, \"TicTacToe.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I export the game state tree into Gephi where I visualize it using a radial axis layout, with each spoke being the move the state can occur on. The visualization offers several interesting insights compiled into the following image I've created. The first insight is that there are no games that end until the 5th move, which is expected since the 2nd player must make at least 2 plays and first player must make 3 to get 3 in a row. We can see that the majority of win occur for the first player around turn 7.\n",
    "\n",
    "![Image](Analysis.jpg)\n",
    "\n",
    "We now begin implementing our agent. For each episode we alternate between playing Xs and Os (going first or second), we play against an agent who will select a random legal move to ensure that we have relatively full coverage of our state space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan  0.  0.  0.  0.  0.  0.  0. nan]\n",
      " [ 0. nan  0.  0.  0.  0.  0.  0. nan]\n",
      " [ 0.  0. nan  0.  0.  0.  0.  0. nan]\n",
      " [ 0.  0.  0. nan  0.  0.  0.  0. nan]\n",
      " [ 0.  0.  0.  0. nan  0.  0.  0. nan]\n",
      " [ 0.  0.  0.  0.  0. nan  0.  0. nan]\n",
      " [ 0.  0.  0.  0.  0.  0. nan  0. nan]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. nan nan]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. nan]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Setup our Q-table\n",
    "\n",
    "#Map board states to Q-Table indices\n",
    "boardToQIndex = {b:i for i, (b, _) in enumerate(boardToState.items())}\n",
    "\n",
    "#create Q-Table full of NaNs with shape numStates x numActions\n",
    "qTable = np.full((len(boardToQIndex), len(actions)), np.nan)\n",
    "\n",
    "#fill legal Q-table actions with 0s\n",
    "for board, state in boardToState.items():\n",
    "    for action, _ in state.children.items():\n",
    "        qTable[boardToQIndex[board], action] = 0\n",
    "\n",
    "print(qTable[-10:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Hyperparamters:\n",
    "\n",
    "numEpisodes = 1000\n",
    "learningRate = 0.01\n",
    "discountFactor = 0.9\n",
    "player = 1              #Which player is being played as\n",
    "\n",
    "for episode in range(numEpisodes):\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab78668dad5b34b81afbaf42b5eb69b6e10e1cebe9b39ab39eaa029e8533d83d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
