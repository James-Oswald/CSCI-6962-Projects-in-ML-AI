{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Reinforcement Learning\n",
    "\n",
    "## Task 1 (50 points): Formulating Real World Problems as MDPs\n",
    "\n",
    "#### Prompt\n",
    "We discussed how we can formulate RL problems as an MDP. Describe any\n",
    "real-world application that can be formulated as an MDP. Describe the state space, action\n",
    "space, transition model, and rewards for that problem. You do not need to be precise in the\n",
    "description of the transition model and reward (no formula is needed). Qualitative description\n",
    "is enough.\n",
    "\n",
    "#### Response\n",
    "\n",
    "## Task 2 (50 points): Reinforcement Learning in concrete domains\n",
    "\n",
    "#### Prompt\n",
    "RL is used in various sectors - Healthcare, recommender systems and trading\n",
    "are a few of those. Pick one of the three areas. Explain one of the problems in any of these\n",
    "domains that can be more effectively solved by reinforcement learning. Find an open-source\n",
    "project (if any) that has addressed this problem. Explain this project in detail.\n",
    "\n",
    "#### Response\n",
    "\n",
    "## Task 3 (100 points): Implementation of Q-Learning for Tik Tak Toe.\n",
    "\n",
    "#### Prompt\n",
    "Implement the game of tic-tac-toe (write a class that implements an agent\n",
    "playing Tic Tac Toe and learning its Q function) using the Q-learning technique (see the\n",
    "resources/links provided in class for more details). Clearly describe your evaluation metric and\n",
    "demonstrate a few runs. You might need to use some online resources to proceed on this. Do\n",
    "not forget to cite those.\n",
    "\n",
    "#### Response\n",
    "One of the main resources I used was [this article](https://towardsdatascience.com/reinforcement-learning-q-learning-with-illegal-actions-from-scratch-19759146c8bf), which describes how you should do Q-learning when your available actions are limited on a state by state basis. I.E., in tic-tak-toe, you are not allowed to put a mark on top of another mark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "actionNames = {\n",
    "    0: \"(0, 0) Upper Left\",\n",
    "    1: \"(1, 0) Upper Center\",\n",
    "    2: \"(2, 0) Upper Right\",\n",
    "    3: \"(0, 1) Middle Left\",\n",
    "    4: \"(1, 1) Middle Center\",\n",
    "    5: \"(2, 1) Middle Right\",\n",
    "    6: \"(0, 2) Lower Left\",\n",
    "    7: \"(1, 2) Lower Center\",\n",
    "    8: \"(2, 2) Lower Right\",\n",
    "}\n",
    "\n",
    "actions = actionNames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Board drawing utility\n",
    "def drawBoard(board, saveName=None):\n",
    "    labelMap = np.vectorize(lambda value: {1:\"X\", -1:\"0\", 0:\" \"}[value])\n",
    "    shapedBoard = np.reshape(board, (3, 3))\n",
    "    labels = labelMap(shapedBoard)\n",
    "    sns.heatmap(shapedBoard, cmap=\"bwr\", annot=labels, \n",
    "        linewidth=.5, linecolor=\"black\", fmt=\"\", cbar=False,\n",
    "        square=True, xticklabels=False, yticklabels=False)\n",
    "    if saveName:\n",
    "        plt.savefig(f\"figs/{saveName}\")\n",
    "\n",
    "#Testing\n",
    "drawBoard([1, 1, 1, 0, -1, 0, -1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of a tik tak toe class, we pre-generate the whole game tree to speed up checking the winner since ticktacktoe is a reasonably small game\n",
    "\n",
    "#Maps board arrays to states to save us space, we reuse state nodes if we encounter a state that already exists\n",
    "boardToState = {}\n",
    "\n",
    "class GameStateNode():\n",
    "    def __init__(self):\n",
    "        #if we are a termination state (leaf node), self.winner is who won, X or O, else is None if draw or not leaf node\n",
    "        self.winner = None  \n",
    "        \n",
    "        #an dict representing the map between actions the child states\n",
    "        self.children = {}\n",
    "        \n",
    "        #The board representation as an array of 9 positions, we can use this for drawing any state\n",
    "        #0 represents an empty box, 1 represents a X, -1 represents a 0\n",
    "        self.board = None\n",
    "\n",
    "\n",
    "#There are only 8 win masks, faster to index all of them rather than add every time\n",
    "winMasks = np.array([\n",
    "    [1, 1, 1, 0, 0, 0, 0, 0, 0], #Horizontal wins\n",
    "    [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "    [1, 0, 0, 1, 0, 0, 1, 0, 0], #Vertical Wins\n",
    "    [0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 1, 0, 0, 0, 1], #Diagonal wins\n",
    "    [0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
    "])\n",
    "\n",
    "def win(board):\n",
    "    for winMask in winMasks:\n",
    "        maskedSum = np.sum(winMask*board)\n",
    "        if maskedSum == 3:\n",
    "            return \"X\"\n",
    "        elif maskedSum == -3:\n",
    "            return \"0\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def buildGameTree(node, board, player):\n",
    "    node.winner = win(board)\n",
    "    if node.winner:             #if the game isn't over, create new branches for all actions\n",
    "        return\n",
    "    for action in actions:\n",
    "        if board[action] == 0:  #if move is legal\n",
    "            newBoard = np.copy(board)\n",
    "            newBoard[action] = player\n",
    "            newBoard.flags.writeable = False\n",
    "            if newBoard.data.tobytes() in boardToState:             #Reuse trees for states we've already seen\n",
    "                newNode = boardToState[newBoard.data.tobytes()]     \n",
    "            else:                                                   #Create new tree if we have not seen it\n",
    "                newNode = GameStateNode()                    \n",
    "                newNode.board = newBoard\n",
    "                buildGameTree(newNode, newBoard, -player)\n",
    "                boardToState[newBoard.data.tobytes()] = newNode\n",
    "            node.children[action] = newNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5477"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = GameTreeNode()\n",
    "emptyBoard = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "buildGameTree(root, emptyBoard, 1)\n",
    "\n",
    "#We expect for tic-tac-toe to get 5477 valid states according to\n",
    "#https://stackoverflow.com/a/25358690/6342516\n",
    "len(boardToState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing my game tree\n",
    "import networkx as nx\n",
    "\n",
    "gameGraph = nx.DiGraph()\n",
    "for _, node in boardToState.items():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab78668dad5b34b81afbaf42b5eb69b6e10e1cebe9b39ab39eaa029e8533d83d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
