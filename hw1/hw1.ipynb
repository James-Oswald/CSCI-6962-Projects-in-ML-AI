{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "data = pd.read_csv('titanic.csv')\n",
    "x = data[[\"Age\", \"Fare\"]].to_numpy()\n",
    "y = data[\"Survived\"].to_numpy()\n",
    "datalen = len(x)\n",
    "split_percent = 0.10    #10% used for testing data \n",
    "split = math.floor(datalen*split_percent)\n",
    "\n",
    "#no need to shuffle, data already randomized in the .csv file\n",
    "x_test = x[:split]\n",
    "x_train = x[split:]\n",
    "y_test = y[:split]\n",
    "y_train = y[split:]\n",
    "\n",
    "#print(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (799,2) not aligned: 2 (dim 0) != 799 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb#ch0000005?line=29'>30</a>\u001b[0m \u001b[39m#training loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb#ch0000005?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb#ch0000005?line=31'>32</a>\u001b[0m     A \u001b[39m=\u001b[39m forward(x_train, weights, bias)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb#ch0000005?line=32'>33</a>\u001b[0m     c \u001b[39m=\u001b[39m cost(y_train, A)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb#ch0000005?line=33'>34</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(epoch) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, Cost: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m c)\n",
      "\u001b[1;32m/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb Cell 5'\u001b[0m in \u001b[0;36mforward\u001b[0;34m(X, weights, bias)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb#ch0000005?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(X, weights, bias):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/james/Desktop/Repos/CSCI-6962-Projects-in-ML-AI/hw1/hw1.ipynb#ch0000005?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sigmoid(np\u001b[39m.\u001b[39;49mdot(weights\u001b[39m.\u001b[39;49mT, X) \u001b[39m+\u001b[39m bias)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,) and (799,2) not aligned: 2 (dim 0) != 799 (dim 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "#hyperparams\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "#init our weight vector based on how many features we have in the data\n",
    "weights : \"np.ndarray[np.floating]\" = np.random.normal(size=x.shape[1])\n",
    "bias : \"np.floating\" = np.random.normal()\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1/(1 + np.exp(-X))\n",
    "\n",
    "def forward(X, weights, bias):\n",
    "    return sigmoid(np.dot(weights.T, X) + bias)\n",
    "\n",
    "def loss(Y, A):\n",
    "    return -(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
    "\n",
    "def cost(Y, A):\n",
    "    return -1/len(A) * np.sum(loss(Y, A))\n",
    "\n",
    "#partial derivitive of cost with respect to weights\n",
    "def dCostWRTw(X, A, Y):\n",
    "    return np.dot(X, (A-Y).T)/len(A)\n",
    "\n",
    "#partial derivitive of cost with respect to bias\n",
    "def dCostWRTb(A, Y):\n",
    "    return np.sum(A-Y)/len(A)\n",
    "\n",
    "\n",
    "#training loop\n",
    "for epoch in range(epochs):\n",
    "    A = forward(x_train, weights, bias)\n",
    "    c = cost(y_train, A)\n",
    "    print(\"Epoch: \" + str(epoch) + \", Cost: \" + c)\n",
    "    dw = dCostWRTw(x_train, A, y_train)\n",
    "    db = dCostWRTb(A, y_train)\n",
    "    weights = weights - learning_rate * dw\n",
    "    bias = bias - learning_rate * db\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
